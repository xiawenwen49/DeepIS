{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = 'retina' # 'retina'\n",
    "import logging\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import copy\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from main.deepis import DeepIS, DiffusionPropagate, Identity\n",
    "from main.models.MLP import MLPTransform\n",
    "from main.models.GraphSAGE import SupervisedGraphSage\n",
    "from main.models.GAT import GAT\n",
    "from main.models.SGC import SGC\n",
    "from main.utils import to_nparray, to_torch, sp2adj_lists\n",
    "from main.training import train_model, get_predictions_new_seeds, PIteration, FeatureCons\n",
    "from main.earlystopping import stopping_args\n",
    "from main.utils import load_dataset, load_latest_ckpt\n",
    "# from im.influspread import IS\n",
    "\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s:%(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "    level=logging.INFO)\n",
    "plt.style.use('seaborn')\n",
    "me_op = lambda x, y: np.mean(np.abs(x - y))\n",
    "te_op = lambda x, y: np.abs(np.sum(x) - np.sum(y))                               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset\n"
   ]
  },
  {
   "source": [
    "## Load from saved SparseGraph object, with added prob_matrix and influ_mats"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key parameters\n",
    "dataset = 'cora_ml' # 'cora_ml', 'citeseer', 'ms_academic', 'pubmed'\n",
    "model_name = 'deepis' # 'deepis', ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<Undirected, unweighted and connected SparseGraph with 15962 edges (no self-loops). Data: adj_matrix (2810x2810), attr_matrix (2810x2879), labels (2810), node_names (2810), attr_names (2879), class_names (7), prob_matrix (2810x2810), influ_mat_list (60x2810x25)>\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((50, 2810, 25), (60, 2810, 25))"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "graph = load_dataset(dataset)\n",
    "print(graph)\n",
    "\n",
    "influ_mat_list = copy.copy(graph.influ_mat_list)\n",
    "graph.influ_mat_list = graph.influ_mat_list[:50]\n",
    "graph.influ_mat_list.shape, influ_mat_list.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# training parameters\n",
    "niter = 4 \n",
    "propagate_model = lambda x, _, y:x[y]\n",
    "fea_constructor = FeatureCons(model_name, niter=niter)\n",
    "fea_constructor.prob_matrix = graph.prob_matrix\n",
    "device = 'cpu' # 'cpu', 'cuda'\n",
    "args_dict = {\n",
    "    'learning_rate': 0.0001,\n",
    "    'λ': 0,\n",
    "    'γ': 0,\n",
    "    'ckpt_dir': Path('./checkpoints'),\n",
    "    'idx_split_args': {'ntraining': 1500, 'nstopping': 500, 'nval': 10, 'seed': 2413340114},  \n",
    "    'test': False,\n",
    "    'device': device,\n",
    "    'print_interval': 1,\n",
    "    'batch_size': None,\n",
    "    \n",
    "}\n",
    "if model_name == 'deepis':\n",
    "    gnn_model = MLPTransform(input_dim=niter+1, hiddenunits=[64, 64], num_classes=1)\n",
    "else:\n",
    "    pass\n",
    "model = DeepIS( gnn_model=gnn_model, propagate=propagate_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model from stratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true,
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " sec)\n",
      "2020-12-13 16:30:45:Epoch 57: Train loss = 0.1123, Train error = 0.1123, early stopping loss = 0.0787, early stopping error = 0.0787, (1.232 sec)\n",
      "2020-12-13 16:30:46:Epoch 58: Train loss = 0.1118, Train error = 0.1118, early stopping loss = 0.0807, early stopping error = 0.0807, (1.069 sec)\n",
      "2020-12-13 16:30:47:Epoch 59: Train loss = 0.1119, Train error = 0.1119, early stopping loss = 0.0788, early stopping error = 0.0788, (1.051 sec)\n",
      "2020-12-13 16:30:48:Epoch 60: Train loss = 0.1125, Train error = 0.1125, early stopping loss = 0.0792, early stopping error = 0.0792, (1.035 sec)\n",
      "2020-12-13 16:30:49:Epoch 61: Train loss = 0.1125, Train error = 0.1125, early stopping loss = 0.0796, early stopping error = 0.0796, (1.020 sec)\n",
      "2020-12-13 16:30:50:Epoch 62: Train loss = 0.1107, Train error = 0.1107, early stopping loss = 0.0812, early stopping error = 0.0812, (1.018 sec)\n",
      "2020-12-13 16:30:51:Epoch 63: Train loss = 0.1141, Train error = 0.1141, early stopping loss = 0.0795, early stopping error = 0.0795, (1.082 sec)\n",
      "2020-12-13 16:30:52:Epoch 64: Train loss = 0.1103, Train error = 0.1103, early stopping loss = 0.0811, early stopping error = 0.0811, (1.013 sec)\n",
      "2020-12-13 16:30:53:Epoch 65: Train loss = 0.1109, Train error = 0.1109, early stopping loss = 0.0818, early stopping error = 0.0818, (1.094 sec)\n",
      "2020-12-13 16:30:55:Epoch 66: Train loss = 0.1099, Train error = 0.1099, early stopping loss = 0.0819, early stopping error = 0.0819, (1.113 sec)\n",
      "2020-12-13 16:30:56:Epoch 67: Train loss = 0.1095, Train error = 0.1095, early stopping loss = 0.0798, early stopping error = 0.0798, (1.249 sec)\n",
      "2020-12-13 16:30:57:Epoch 68: Train loss = 0.1090, Train error = 0.1090, early stopping loss = 0.0777, early stopping error = 0.0777, (1.092 sec)\n",
      "2020-12-13 16:30:58:Epoch 69: Train loss = 0.1110, Train error = 0.1110, early stopping loss = 0.0784, early stopping error = 0.0784, (1.068 sec)\n",
      "2020-12-13 16:30:59:Epoch 70: Train loss = 0.1097, Train error = 0.1097, early stopping loss = 0.0779, early stopping error = 0.0779, (1.107 sec)\n",
      "2020-12-13 16:31:00:Epoch 71: Train loss = 0.1093, Train error = 0.1093, early stopping loss = 0.0827, early stopping error = 0.0827, (1.070 sec)\n",
      "2020-12-13 16:31:01:Epoch 72: Train loss = 0.1104, Train error = 0.1104, early stopping loss = 0.0798, early stopping error = 0.0798, (1.037 sec)\n",
      "2020-12-13 16:31:02:Epoch 73: Train loss = 0.1088, Train error = 0.1088, early stopping loss = 0.0835, early stopping error = 0.0835, (1.073 sec)\n",
      "2020-12-13 16:31:03:Epoch 74: Train loss = 0.1084, Train error = 0.1084, early stopping loss = 0.0755, early stopping error = 0.0755, (1.151 sec)\n",
      "2020-12-13 16:31:04:Epoch 75: Train loss = 0.1091, Train error = 0.1091, early stopping loss = 0.0789, early stopping error = 0.0789, (1.077 sec)\n",
      "2020-12-13 16:31:06:Epoch 76: Train loss = 0.1097, Train error = 0.1097, early stopping loss = 0.0790, early stopping error = 0.0790, (1.114 sec)\n",
      "2020-12-13 16:31:07:Epoch 77: Train loss = 0.1091, Train error = 0.1091, early stopping loss = 0.0775, early stopping error = 0.0775, (1.186 sec)\n",
      "2020-12-13 16:31:08:Epoch 78: Train loss = 0.1095, Train error = 0.1095, early stopping loss = 0.0751, early stopping error = 0.0751, (1.115 sec)\n",
      "2020-12-13 16:31:09:Epoch 79: Train loss = 0.1093, Train error = 0.1093, early stopping loss = 0.0739, early stopping error = 0.0739, (1.015 sec)\n",
      "2020-12-13 16:31:10:Epoch 80: Train loss = 0.1081, Train error = 0.1081, early stopping loss = 0.0739, early stopping error = 0.0739, (1.008 sec)\n",
      "2020-12-13 16:31:11:Epoch 81: Train loss = 0.1088, Train error = 0.1088, early stopping loss = 0.0748, early stopping error = 0.0748, (1.038 sec)\n",
      "2020-12-13 16:31:12:Epoch 82: Train loss = 0.1081, Train error = 0.1081, early stopping loss = 0.0765, early stopping error = 0.0765, (1.094 sec)\n",
      "2020-12-13 16:31:13:Epoch 83: Train loss = 0.1080, Train error = 0.1080, early stopping loss = 0.0773, early stopping error = 0.0773, (1.023 sec)\n",
      "2020-12-13 16:31:14:Epoch 84: Train loss = 0.1067, Train error = 0.1067, early stopping loss = 0.0770, early stopping error = 0.0770, (1.010 sec)\n",
      "2020-12-13 16:31:15:Epoch 85: Train loss = 0.1068, Train error = 0.1068, early stopping loss = 0.0776, early stopping error = 0.0776, (0.959 sec)\n",
      "2020-12-13 16:31:16:Epoch 86: Train loss = 0.1092, Train error = 0.1092, early stopping loss = 0.0748, early stopping error = 0.0748, (1.025 sec)\n",
      "2020-12-13 16:31:17:Epoch 87: Train loss = 0.1059, Train error = 0.1059, early stopping loss = 0.0760, early stopping error = 0.0760, (1.337 sec)\n",
      "2020-12-13 16:31:18:Epoch 88: Train loss = 0.1095, Train error = 0.1095, early stopping loss = 0.0728, early stopping error = 0.0728, (0.982 sec)\n",
      "2020-12-13 16:31:20:Epoch 89: Train loss = 0.1068, Train error = 0.1068, early stopping loss = 0.0760, early stopping error = 0.0760, (1.398 sec)\n",
      "2020-12-13 16:31:21:Epoch 90: Train loss = 0.1096, Train error = 0.1096, early stopping loss = 0.0775, early stopping error = 0.0775, (1.513 sec)\n",
      "2020-12-13 16:31:22:Epoch 91: Train loss = 0.1085, Train error = 0.1085, early stopping loss = 0.0698, early stopping error = 0.0698, (1.134 sec)\n",
      "2020-12-13 16:31:23:Epoch 92: Train loss = 0.1071, Train error = 0.1071, early stopping loss = 0.0757, early stopping error = 0.0757, (1.063 sec)\n",
      "2020-12-13 16:31:25:Epoch 93: Train loss = 0.1070, Train error = 0.1070, early stopping loss = 0.0747, early stopping error = 0.0747, (1.194 sec)\n",
      "2020-12-13 16:31:26:Epoch 94: Train loss = 0.1084, Train error = 0.1084, early stopping loss = 0.0741, early stopping error = 0.0741, (1.150 sec)\n",
      "2020-12-13 16:31:27:Epoch 95: Train loss = 0.1101, Train error = 0.1101, early stopping loss = 0.0696, early stopping error = 0.0696, (1.203 sec)\n",
      "2020-12-13 16:31:28:Epoch 96: Train loss = 0.1059, Train error = 0.1059, early stopping loss = 0.0725, early stopping error = 0.0725, (1.123 sec)\n",
      "2020-12-13 16:31:29:Epoch 97: Train loss = 0.1067, Train error = 0.1067, early stopping loss = 0.0720, early stopping error = 0.0720, (1.109 sec)\n",
      "2020-12-13 16:31:30:Epoch 98: Train loss = 0.1063, Train error = 0.1063, early stopping loss = 0.0752, early stopping error = 0.0752, (1.174 sec)\n",
      "2020-12-13 16:31:32:Epoch 99: Train loss = 0.1056, Train error = 0.1056, early stopping loss = 0.0760, early stopping error = 0.0760, (1.120 sec)\n",
      "2020-12-13 16:31:33:Epoch 100: Train loss = 0.1085, Train error = 0.1085, early stopping loss = 0.0742, early stopping error = 0.0742, (1.142 sec)\n",
      "2020-12-13 16:31:34:Epoch 101: Train loss = 0.1046, Train error = 0.1046, early stopping loss = 0.0727, early stopping error = 0.0727, (1.070 sec)\n",
      "2020-12-13 16:31:35:Epoch 102: Train loss = 0.1081, Train error = 0.1081, early stopping loss = 0.0695, early stopping error = 0.0695, (0.982 sec)\n",
      "2020-12-13 16:31:36:Epoch 103: Train loss = 0.1056, Train error = 0.1056, early stopping loss = 0.0756, early stopping error = 0.0756, (1.022 sec)\n",
      "2020-12-13 16:31:37:Epoch 104: Train loss = 0.1065, Train error = 0.1065, early stopping loss = 0.0758, early stopping error = 0.0758, (0.998 sec)\n",
      "2020-12-13 16:31:38:Epoch 105: Train loss = 0.1071, Train error = 0.1071, early stopping loss = 0.0708, early stopping error = 0.0708, (0.965 sec)\n",
      "2020-12-13 16:31:39:Epoch 106: Train loss = 0.1062, Train error = 0.1062, early stopping loss = 0.0724, early stopping error = 0.0724, (1.026 sec)\n",
      "2020-12-13 16:31:40:Epoch 107: Train loss = 0.1032, Train error = 0.1032, early stopping loss = 0.0740, early stopping error = 0.0740, (0.941 sec)\n",
      "2020-12-13 16:31:41:Epoch 108: Train loss = 0.1069, Train error = 0.1069, early stopping loss = 0.0711, early stopping error = 0.0711, (1.042 sec)\n",
      "2020-12-13 16:31:42:Epoch 109: Train loss = 0.1051, Train error = 0.1051, early stopping loss = 0.0728, early stopping error = 0.0728, (1.103 sec)\n",
      "2020-12-13 16:31:43:Epoch 110: Train loss = 0.1059, Train error = 0.1059, early stopping loss = 0.0753, early stopping error = 0.0753, (1.144 sec)\n",
      "2020-12-13 16:31:44:Epoch 111: Train loss = 0.1057, Train error = 0.1057, early stopping loss = 0.0707, early stopping error = 0.0707, (1.147 sec)\n",
      "2020-12-13 16:31:45:Epoch 112: Train loss = 0.1040, Train error = 0.1040, early stopping loss = 0.0746, early stopping error = 0.0746, (1.100 sec)\n",
      "2020-12-13 16:31:46:Epoch 113: Train loss = 0.1072, Train error = 0.1072, early stopping loss = 0.0727, early stopping error = 0.0727, (1.127 sec)\n",
      "2020-12-13 16:31:47:Epoch 114: Train loss = 0.1064, Train error = 0.1064, early stopping loss = 0.0669, early stopping error = 0.0669, (1.093 sec)\n",
      "2020-12-13 16:31:49:Epoch 115: Train loss = 0.1063, Train error = 0.1063, early stopping loss = 0.0727, early stopping error = 0.0727, (1.064 sec)\n",
      "2020-12-13 16:31:50:Epoch 116: Train loss = 0.1068, Train error = 0.1068, early stopping loss = 0.0701, early stopping error = 0.0701, (1.029 sec)\n",
      "2020-12-13 16:31:51:Epoch 117: Train loss = 0.1067, Train error = 0.1067, early stopping loss = 0.0698, early stopping error = 0.0698, (1.169 sec)\n",
      "2020-12-13 16:31:52:Epoch 118: Train loss = 0.1053, Train error = 0.1053, early stopping loss = 0.0677, early stopping error = 0.0677, (1.198 sec)\n",
      "2020-12-13 16:31:53:Epoch 119: Train loss = 0.1043, Train error = 0.1043, early stopping loss = 0.0727, early stopping error = 0.0727, (1.144 sec)\n",
      "2020-12-13 16:31:54:Epoch 120: Train loss = 0.1058, Train error = 0.1058, early stopping loss = 0.0726, early stopping error = 0.0726, (1.111 sec)\n",
      "2020-12-13 16:31:55:Epoch 121: Train loss = 0.1069, Train error = 0.1069, early stopping loss = 0.0709, early stopping error = 0.0709, (1.034 sec)\n",
      "2020-12-13 16:31:56:Epoch 122: Train loss = 0.1067, Train error = 0.1067, early stopping loss = 0.0722, early stopping error = 0.0722, (1.158 sec)\n",
      "2020-12-13 16:31:57:Epoch 123: Train loss = 0.1038, Train error = 0.1038, early stopping loss = 0.0720, early stopping error = 0.0720, (1.104 sec)\n",
      "2020-12-13 16:31:59:Epoch 124: Train loss = 0.1055, Train error = 0.1055, early stopping loss = 0.0709, early stopping error = 0.0709, (1.144 sec)\n",
      "2020-12-13 16:32:00:Epoch 125: Train loss = 0.1029, Train error = 0.1029, early stopping loss = 0.0755, early stopping error = 0.0755, (1.070 sec)\n",
      "2020-12-13 16:32:01:Epoch 126: Train loss = 0.1057, Train error = 0.1057, early stopping loss = 0.0704, early stopping error = 0.0704, (1.020 sec)\n",
      "2020-12-13 16:32:02:Epoch 127: Train loss = 0.1047, Train error = 0.1047, early stopping loss = 0.0749, early stopping error = 0.0749, (1.080 sec)\n",
      "2020-12-13 16:32:03:Epoch 128: Train loss = 0.1072, Train error = 0.1072, early stopping loss = 0.0708, early stopping error = 0.0708, (1.099 sec)\n",
      "2020-12-13 16:32:04:Epoch 129: Train loss = 0.1070, Train error = 0.1070, early stopping loss = 0.0707, early stopping error = 0.0707, (1.024 sec)\n",
      "2020-12-13 16:32:05:Epoch 130: Train loss = 0.1080, Train error = 0.1080, early stopping loss = 0.0721, early stopping error = 0.0721, (1.085 sec)\n",
      "2020-12-13 16:32:06:Epoch 131: Train loss = 0.1042, Train error = 0.1042, early stopping loss = 0.0701, early stopping error = 0.0701, (1.065 sec)\n",
      "2020-12-13 16:32:07:Epoch 132: Train loss = 0.1024, Train error = 0.1024, early stopping loss = 0.0746, early stopping error = 0.0746, (1.086 sec)\n",
      "2020-12-13 16:32:08:Epoch 133: Train loss = 0.1038, Train error = 0.1038, early stopping loss = 0.0724, early stopping error = 0.0724, (1.146 sec)\n",
      "2020-12-13 16:32:09:Epoch 134: Train loss = 0.1053, Train error = 0.1053, early stopping loss = 0.0690, early stopping error = 0.0690, (1.152 sec)\n",
      "2020-12-13 16:32:11:Epoch 135: Train loss = 0.1066, Train error = 0.1066, early stopping loss = 0.0672, early stopping error = 0.0672, (1.076 sec)\n",
      "2020-12-13 16:32:12:Epoch 136: Train loss = 0.1047, Train error = 0.1047, early stopping loss = 0.0719, early stopping error = 0.0719, (1.144 sec)\n",
      "2020-12-13 16:32:13:Epoch 137: Train loss = 0.1067, Train error = 0.1067, early stopping loss = 0.0658, early stopping error = 0.0658, (1.010 sec)\n",
      "2020-12-13 16:32:14:Epoch 138: Train loss = 0.1055, Train error = 0.1055, early stopping loss = 0.0716, early stopping error = 0.0716, (1.070 sec)\n",
      "2020-12-13 16:32:15:Epoch 139: Train loss = 0.1047, Train error = 0.1047, early stopping loss = 0.0660, early stopping error = 0.0660, (1.170 sec)\n",
      "2020-12-13 16:32:16:Epoch 140: Train loss = 0.1067, Train error = 0.1067, early stopping loss = 0.0752, early stopping error = 0.0752, (1.041 sec)\n",
      "2020-12-13 16:32:17:Epoch 141: Train loss = 0.1062, Train error = 0.1062, early stopping loss = 0.0694, early stopping error = 0.0694, (1.183 sec)\n",
      "2020-12-13 16:32:18:Epoch 142: Train loss = 0.1048, Train error = 0.1048, early stopping loss = 0.0738, early stopping error = 0.0738, (1.126 sec)\n",
      "2020-12-13 16:32:19:Epoch 143: Train loss = 0.1041, Train error = 0.1041, early stopping loss = 0.0716, early stopping error = 0.0716, (1.041 sec)\n",
      "2020-12-13 16:32:20:Epoch 144: Train loss = 0.1059, Train error = 0.1059, early stopping loss = 0.0714, early stopping error = 0.0714, (1.205 sec)\n",
      "2020-12-13 16:32:22:Epoch 145: Train loss = 0.1056, Train error = 0.1056, early stopping loss = 0.0686, early stopping error = 0.0686, (1.064 sec)\n",
      "2020-12-13 16:32:23:Epoch 146: Train loss = 0.1037, Train error = 0.1037, early stopping loss = 0.0738, early stopping error = 0.0738, (1.091 sec)\n",
      "2020-12-13 16:32:24:Epoch 147: Train loss = 0.1053, Train error = 0.1053, early stopping loss = 0.0684, early stopping error = 0.0684, (1.089 sec)\n",
      "2020-12-13 16:32:25:Epoch 148: Train loss = 0.1032, Train error = 0.1032, early stopping loss = 0.0690, early stopping error = 0.0690, (0.979 sec)\n",
      "2020-12-13 16:32:26:Epoch 149: Train loss = 0.1065, Train error = 0.1065, early stopping loss = 0.0692, early stopping error = 0.0692, (1.084 sec)\n",
      "2020-12-13 16:32:27:Epoch 150: Train loss = 0.1038, Train error = 0.1038, early stopping loss = 0.0760, early stopping error = 0.0760, (1.104 sec)\n",
      "2020-12-13 16:32:28:Epoch 151: Train loss = 0.1047, Train error = 0.1047, early stopping loss = 0.0688, early stopping error = 0.0688, (0.974 sec)\n",
      "2020-12-13 16:32:29:Epoch 152: Train loss = 0.1037, Train error = 0.1037, early stopping loss = 0.0731, early stopping error = 0.0731, (1.083 sec)\n",
      "2020-12-13 16:32:30:Epoch 153: Train loss = 0.1056, Train error = 0.1056, early stopping loss = 0.0687, early stopping error = 0.0687, (1.117 sec)\n",
      "2020-12-13 16:32:31:Epoch 154: Train loss = 0.1047, Train error = 0.1047, early stopping loss = 0.0706, early stopping error = 0.0706, (1.095 sec)\n",
      "2020-12-13 16:32:32:Epoch 155: Train loss = 0.1047, Train error = 0.1047, early stopping loss = 0.0760, early stopping error = 0.0760, (1.205 sec)\n",
      "2020-12-13 16:32:34:Epoch 156: Train loss = 0.1042, Train error = 0.1042, early stopping loss = 0.0715, early stopping error = 0.0715, (1.161 sec)\n",
      "2020-12-13 16:32:35:Epoch 157: Train loss = 0.1020, Train error = 0.1020, early stopping loss = 0.0720, early stopping error = 0.0720, (1.132 sec)\n",
      "2020-12-13 16:32:36:Epoch 158: Train loss = 0.1042, Train error = 0.1042, early stopping loss = 0.0703, early stopping error = 0.0703, (1.112 sec)\n",
      "2020-12-13 16:32:37:Epoch 159: Train loss = 0.1053, Train error = 0.1053, early stopping loss = 0.0678, early stopping error = 0.0678, (1.063 sec)\n",
      "2020-12-13 16:32:38:Epoch 160: Train loss = 0.1049, Train error = 0.1049, early stopping loss = 0.0675, early stopping error = 0.0675, (1.080 sec)\n",
      "2020-12-13 16:32:39:Epoch 161: Train loss = 0.1041, Train error = 0.1041, early stopping loss = 0.0652, early stopping error = 0.0652, (1.114 sec)\n",
      "2020-12-13 16:32:40:Epoch 162: Train loss = 0.1030, Train error = 0.1030, early stopping loss = 0.0710, early stopping error = 0.0710, (1.068 sec)\n",
      "2020-12-13 16:32:41:Epoch 163: Train loss = 0.1048, Train error = 0.1048, early stopping loss = 0.0743, early stopping error = 0.0743, (1.117 sec)\n",
      "2020-12-13 16:32:42:Epoch 164: Train loss = 0.1042, Train error = 0.1042, early stopping loss = 0.0696, early stopping error = 0.0696, (1.091 sec)\n",
      "2020-12-13 16:32:43:Epoch 165: Train loss = 0.1050, Train error = 0.1050, early stopping loss = 0.0694, early stopping error = 0.0694, (1.087 sec)\n",
      "2020-12-13 16:32:44:Epoch 166: Train loss = 0.1039, Train error = 0.1039, early stopping loss = 0.0688, early stopping error = 0.0688, (1.007 sec)\n",
      "2020-12-13 16:32:45:Epoch 167: Train loss = 0.1039, Train error = 0.1039, early stopping loss = 0.0709, early stopping error = 0.0709, (1.018 sec)\n",
      "2020-12-13 16:32:46:Epoch 168: Train loss = 0.1041, Train error = 0.1041, early stopping loss = 0.0715, early stopping error = 0.0715, (1.066 sec)\n",
      "2020-12-13 16:32:48:Epoch 169: Train loss = 0.1016, Train error = 0.1016, early stopping loss = 0.0680, early stopping error = 0.0680, (1.016 sec)\n",
      "2020-12-13 16:32:48:Epoch 170: Train loss = 0.1040, Train error = 0.1040, early stopping loss = 0.0728, early stopping error = 0.0728, (0.962 sec)\n",
      "2020-12-13 16:32:50:Epoch 171: Train loss = 0.1034, Train error = 0.1034, early stopping loss = 0.0724, early stopping error = 0.0724, (1.087 sec)\n",
      "2020-12-13 16:32:51:Epoch 172: Train loss = 0.1033, Train error = 0.1033, early stopping loss = 0.0698, early stopping error = 0.0698, (1.134 sec)\n",
      "2020-12-13 16:32:52:Epoch 173: Train loss = 0.1041, Train error = 0.1041, early stopping loss = 0.0734, early stopping error = 0.0734, (1.099 sec)\n",
      "2020-12-13 16:32:53:Epoch 174: Train loss = 0.1037, Train error = 0.1037, early stopping loss = 0.0664, early stopping error = 0.0664, (1.183 sec)\n",
      "2020-12-13 16:32:54:Epoch 175: Train loss = 0.1027, Train error = 0.1027, early stopping loss = 0.0691, early stopping error = 0.0691, (1.107 sec)\n",
      "2020-12-13 16:32:55:Epoch 176: Train loss = 0.1038, Train error = 0.1038, early stopping loss = 0.0681, early stopping error = 0.0681, (1.147 sec)\n",
      "2020-12-13 16:32:56:Epoch 177: Train loss = 0.1044, Train error = 0.1044, early stopping loss = 0.0692, early stopping error = 0.0692, (1.186 sec)\n",
      "2020-12-13 16:32:58:Epoch 178: Train loss = 0.1035, Train error = 0.1035, early stopping loss = 0.0730, early stopping error = 0.0730, (1.096 sec)\n",
      "2020-12-13 16:32:59:Epoch 179: Train loss = 0.1010, Train error = 0.1010, early stopping loss = 0.0741, early stopping error = 0.0741, (1.129 sec)\n",
      "2020-12-13 16:33:00:Epoch 180: Train loss = 0.1025, Train error = 0.1025, early stopping loss = 0.0698, early stopping error = 0.0698, (1.141 sec)\n",
      "2020-12-13 16:33:01:Epoch 181: Train loss = 0.1044, Train error = 0.1044, early stopping loss = 0.0700, early stopping error = 0.0700, (1.035 sec)\n",
      "2020-12-13 16:33:02:Epoch 182: Train loss = 0.1041, Train error = 0.1041, early stopping loss = 0.0677, early stopping error = 0.0677, (1.094 sec)\n",
      "2020-12-13 16:33:03:Epoch 183: Train loss = 0.1024, Train error = 0.1024, early stopping loss = 0.0698, early stopping error = 0.0698, (1.032 sec)\n",
      "2020-12-13 16:33:04:Epoch 184: Train loss = 0.1030, Train error = 0.1030, early stopping loss = 0.0719, early stopping error = 0.0719, (1.087 sec)\n",
      "2020-12-13 16:33:05:Epoch 185: Train loss = 0.1009, Train error = 0.1009, early stopping loss = 0.0753, early stopping error = 0.0753, (1.026 sec)\n",
      "2020-12-13 16:33:06:Epoch 186: Train loss = 0.1033, Train error = 0.1033, early stopping loss = 0.0696, early stopping error = 0.0696, (0.905 sec)\n",
      "2020-12-13 16:33:07:Epoch 187: Train loss = 0.1024, Train error = 0.1024, early stopping loss = 0.0731, early stopping error = 0.0731, (0.963 sec)\n",
      "2020-12-13 16:33:08:Epoch 188: Train loss = 0.1045, Train error = 0.1045, early stopping loss = 0.0667, early stopping error = 0.0667, (0.949 sec)\n",
      "2020-12-13 16:33:09:Epoch 189: Train loss = 0.1055, Train error = 0.1055, early stopping loss = 0.0667, early stopping error = 0.0667, (0.904 sec)\n",
      "2020-12-13 16:33:10:Epoch 190: Train loss = 0.1030, Train error = 0.1030, early stopping loss = 0.0673, early stopping error = 0.0673, (0.957 sec)\n",
      "2020-12-13 16:33:11:Epoch 191: Train loss = 0.1034, Train error = 0.1034, early stopping loss = 0.0684, early stopping error = 0.0684, (0.948 sec)\n",
      "2020-12-13 16:33:11:Last epoch: 191, best epoch: 161 (219.487 sec)\n",
      "2020-12-13 16:33:11:Early stopping error: 0.06535126002445817\n",
      "2020-12-13 16:33:11:Validation mean error: 0.07795287606865169\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'checkpoints/deepis_cora_ml_2020-12-13_16-29-31_161'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-8705600a24f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfea_constructor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0margs_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/workspace/DeepIS-master/main/training.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model_name, model, fea_constructor, graph, learning_rate, λ, γ, ckpt_dir, idx_split_args, stopping_args, test, device, torch_seed, print_interval, batch_size)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0mckpt_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{}_{}_{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_time_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_dir\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mckpt_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m     return (\n\u001b[1;32m    250\u001b[0m      model, result)\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[0m_check_dill_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'checkpoints/deepis_cora_ml_2020-12-13_16-29-31_161'"
     ]
    }
   ],
   "source": [
    "model, result = train_model(model_name + '_' + dataset, model, fea_constructor, graph, **args_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction on NEW SEEDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<Undirected, unweighted and connected SparseGraph with 15962 edges (no self-loops). Data: adj_matrix (2810x2810), attr_matrix (2810x2879), labels (2810), node_names (2810), attr_names (2879), class_names (7), prob_matrix (2810x2810), influ_mat_list (60x2810x25)>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "dataset = 'cora_ml'\n",
    "graph = load_dataset(dataset)\n",
    "influ_mat_list = copy.copy(graph.influ_mat_list)\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics\n",
    "me = lambda x, y: np.mean(np.abs(x - y))\n",
    "te = lambda x, y: np.abs(np.sum(x) - np.sum(y)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mean error: 0.018692823674057526\ntotal error: 14.633356017719734\nCPU times: user 938 ms, sys: 50.7 ms, total: 988 ms\nWall time: 419 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "influ_mat = influ_mat_list[58]\n",
    "seed_vec = influ_mat[:, 0]\n",
    "seed_idx = np.argwhere(seed_vec == 1) # used by PIteration\n",
    "influ_vec = influ_mat[:, -1]\n",
    "\n",
    "fea_constructor.prob_matrix = graph.prob_matrix\n",
    "preds = get_predictions_new_seeds(model, fea_constructor, seed_vec, np.arange(len(seed_vec)))\n",
    "final_preds = PIteration(graph.prob_matrix, preds, seed_idx, True, 2)\n",
    "\n",
    "print('mean error:', me(influ_vec, final_preds))\n",
    "print('total error:', te(influ_vec, final_preds))\n"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}